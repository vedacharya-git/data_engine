{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTGAN From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data in pandas dataframe\n",
    "current_directory = os.path.abspath(os.getcwd())\n",
    "parent_directory = os.path.join(current_directory, '..')\n",
    "grandparent_directory = os.path.join(parent_directory, '..')\n",
    "data_directory = os.path.join(grandparent_directory, 'data')\n",
    "csv_path = os.path.join(data_directory, 'healthcare_dataset.csv')\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>Tiffany Ramirez</td>\n",
       "      <td>Ruben Burns</td>\n",
       "      <td>Chad Byrd</td>\n",
       "      <td>Antonio Frederick</td>\n",
       "      <td>Mrs. Brandy Flowers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>81</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>Female</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blood Type</th>\n",
       "      <td>O-</td>\n",
       "      <td>O+</td>\n",
       "      <td>B-</td>\n",
       "      <td>B-</td>\n",
       "      <td>O-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical Condition</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>Arthritis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Admission</th>\n",
       "      <td>2022-11-17</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2021-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>Patrick Parker</td>\n",
       "      <td>Diane Jackson</td>\n",
       "      <td>Paul Baker</td>\n",
       "      <td>Brian Chandler</td>\n",
       "      <td>Dustin Griffin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hospital</th>\n",
       "      <td>Wallace-Hamilton</td>\n",
       "      <td>Burke, Griffin and Cooper</td>\n",
       "      <td>Walton LLC</td>\n",
       "      <td>Garcia Ltd</td>\n",
       "      <td>Jones, Brown and Murray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insurance Provider</th>\n",
       "      <td>Medicare</td>\n",
       "      <td>UnitedHealthcare</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>UnitedHealthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Billing Amount</th>\n",
       "      <td>37490.983364</td>\n",
       "      <td>47304.064845</td>\n",
       "      <td>36874.896997</td>\n",
       "      <td>23303.322092</td>\n",
       "      <td>18086.344184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Room Number</th>\n",
       "      <td>146</td>\n",
       "      <td>404</td>\n",
       "      <td>292</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admission Type</th>\n",
       "      <td>Elective</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Urgent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharge Date</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2021-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medication</th>\n",
       "      <td>Aspirin</td>\n",
       "      <td>Lipitor</td>\n",
       "      <td>Lipitor</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Paracetamol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Results</th>\n",
       "      <td>Inconclusive</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0                          1             2  \\\n",
       "Name                 Tiffany Ramirez                Ruben Burns     Chad Byrd   \n",
       "Age                               81                         35            61   \n",
       "Gender                        Female                       Male          Male   \n",
       "Blood Type                        O-                         O+            B-   \n",
       "Medical Condition           Diabetes                     Asthma       Obesity   \n",
       "Date of Admission         2022-11-17                 2023-06-01    2019-01-09   \n",
       "Doctor                Patrick Parker              Diane Jackson    Paul Baker   \n",
       "Hospital            Wallace-Hamilton  Burke, Griffin and Cooper    Walton LLC   \n",
       "Insurance Provider          Medicare           UnitedHealthcare      Medicare   \n",
       "Billing Amount          37490.983364               47304.064845  36874.896997   \n",
       "Room Number                      146                        404           292   \n",
       "Admission Type              Elective                  Emergency     Emergency   \n",
       "Discharge Date            2022-12-01                 2023-06-15    2019-02-08   \n",
       "Medication                   Aspirin                    Lipitor       Lipitor   \n",
       "Test Results            Inconclusive                     Normal        Normal   \n",
       "\n",
       "                                    3                        4  \n",
       "Name                Antonio Frederick      Mrs. Brandy Flowers  \n",
       "Age                                49                       51  \n",
       "Gender                           Male                     Male  \n",
       "Blood Type                         B-                       O-  \n",
       "Medical Condition              Asthma                Arthritis  \n",
       "Date of Admission          2020-05-02               2021-07-09  \n",
       "Doctor                 Brian Chandler           Dustin Griffin  \n",
       "Hospital                   Garcia Ltd  Jones, Brown and Murray  \n",
       "Insurance Provider           Medicare         UnitedHealthcare  \n",
       "Billing Amount           23303.322092             18086.344184  \n",
       "Room Number                       480                      477  \n",
       "Admission Type                 Urgent                   Urgent  \n",
       "Discharge Date             2020-05-03               2021-08-02  \n",
       "Medication                 Penicillin              Paracetamol  \n",
       "Test Results                 Abnormal                   Normal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking data types and basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                   9378\n",
       "Age                      68\n",
       "Gender                    2\n",
       "Blood Type                8\n",
       "Medical Condition         6\n",
       "Date of Admission      1815\n",
       "Doctor                 9416\n",
       "Hospital               8639\n",
       "Insurance Provider        5\n",
       "Billing Amount        10000\n",
       "Room Number             400\n",
       "Admission Type            3\n",
       "Discharge Date         1834\n",
       "Medication                5\n",
       "Test Results              3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropCols = ['Name', 'Date of Admission', 'Doctor', 'Hospital', 'Insurance Provider', 'Room Number', 'Discharge Date']\n",
    "df.drop(dropCols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                     68\n",
       "Gender                   2\n",
       "Blood Type               8\n",
       "Medical Condition        6\n",
       "Billing Amount       10000\n",
       "Admission Type           3\n",
       "Medication               5\n",
       "Test Results             3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising and One-Hot Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender',\n",
       " 'Blood Type',\n",
       " 'Medical Condition',\n",
       " 'Admission Type',\n",
       " 'Medication',\n",
       " 'Test Results']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objCols = list(df.select_dtypes(include='object').columns)\n",
    "objCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ved/external/miniconda3/envs/da/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, sparse=False, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, sparse=False, sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first', sparse=False, sparse_output=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE = OneHotEncoder(sparse=False, drop='first')\n",
    "OHE.fit(data_train[objCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Billing Amount</th>\n",
       "      <td>37490.983364</td>\n",
       "      <td>47304.064845</td>\n",
       "      <td>36874.896997</td>\n",
       "      <td>23303.322092</td>\n",
       "      <td>18086.344184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0             1             2             3  \\\n",
       "Age                81.000000     35.000000     61.000000     49.000000   \n",
       "Billing Amount  37490.983364  47304.064845  36874.896997  23303.322092   \n",
       "0                   0.000000      1.000000      1.000000      1.000000   \n",
       "1                   0.000000      0.000000      0.000000      0.000000   \n",
       "2                   0.000000      0.000000      0.000000      0.000000   \n",
       "3                   0.000000      0.000000      0.000000      0.000000   \n",
       "4                   0.000000      0.000000      0.000000      0.000000   \n",
       "5                   0.000000      0.000000      1.000000      1.000000   \n",
       "6                   0.000000      1.000000      0.000000      0.000000   \n",
       "7                   1.000000      0.000000      0.000000      0.000000   \n",
       "8                   0.000000      1.000000      0.000000      1.000000   \n",
       "9                   0.000000      0.000000      0.000000      0.000000   \n",
       "10                  1.000000      0.000000      0.000000      0.000000   \n",
       "11                  0.000000      0.000000      0.000000      0.000000   \n",
       "12                  0.000000      0.000000      1.000000      0.000000   \n",
       "13                  0.000000      1.000000      1.000000      0.000000   \n",
       "14                  0.000000      0.000000      0.000000      1.000000   \n",
       "15                  0.000000      0.000000      0.000000      0.000000   \n",
       "16                  0.000000      1.000000      1.000000      0.000000   \n",
       "17                  0.000000      0.000000      0.000000      0.000000   \n",
       "18                  0.000000      0.000000      0.000000      1.000000   \n",
       "19                  1.000000      0.000000      0.000000      0.000000   \n",
       "20                  0.000000      1.000000      1.000000      0.000000   \n",
       "\n",
       "                           4  \n",
       "Age                51.000000  \n",
       "Billing Amount  18086.344184  \n",
       "0                   1.000000  \n",
       "1                   0.000000  \n",
       "2                   0.000000  \n",
       "3                   0.000000  \n",
       "4                   0.000000  \n",
       "5                   0.000000  \n",
       "6                   0.000000  \n",
       "7                   1.000000  \n",
       "8                   0.000000  \n",
       "9                   0.000000  \n",
       "10                  0.000000  \n",
       "11                  0.000000  \n",
       "12                  0.000000  \n",
       "13                  0.000000  \n",
       "14                  1.000000  \n",
       "15                  0.000000  \n",
       "16                  0.000000  \n",
       "17                  1.000000  \n",
       "18                  0.000000  \n",
       "19                  0.000000  \n",
       "20                  1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.concat([data_train, pd.DataFrame(OHE.transform(data_train[objCols]))], axis=1)\n",
    "data_train.drop(objCols, axis=1, inplace=True)\n",
    "data_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gender_Male', 'Blood Type_A-', 'Blood Type_AB+', 'Blood Type_AB-',\n",
       "       'Blood Type_B+', 'Blood Type_B-', 'Blood Type_O+', 'Blood Type_O-',\n",
       "       'Medical Condition_Asthma', 'Medical Condition_Cancer',\n",
       "       'Medical Condition_Diabetes', 'Medical Condition_Hypertension',\n",
       "       'Medical Condition_Obesity', 'Admission Type_Emergency',\n",
       "       'Admission Type_Urgent', 'Medication_Ibuprofen',\n",
       "       'Medication_Lipitor', 'Medication_Paracetamol',\n",
       "       'Medication_Penicillin', 'Test Results_Inconclusive',\n",
       "       'Test Results_Normal'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_column_names = OHE.get_feature_names_out(input_features=objCols)\n",
    "encoded_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Billing Amount']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numCols = list(df.select_dtypes(exclude='object').columns)\n",
    "numCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ved/external/miniconda3/envs/da/lib/python3.10/site-packages/sklearn/mixture/_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesianGaussianMixture(n_components=10, random_state=0,\n",
       "                        weight_concentration_prior=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesianGaussianMixture</label><div class=\"sk-toggleable__content\"><pre>BayesianGaussianMixture(n_components=10, random_state=0,\n",
       "                        weight_concentration_prior=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesianGaussianMixture(n_components=10, random_state=0,\n",
       "                        weight_concentration_prior=0.001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BGM = BayesianGaussianMixture(n_components=10, weight_concentration_prior_type='dirichlet_process', weight_concentration_prior=0.001, random_state=0)\n",
    "BGM.fit(data_train[numCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_cols = ['Component_' + str(i) for i in range(BGM.n_components)]\n",
    "probabilities = BGM.predict_proba(data_train[numCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[component_cols] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>8.100000e+01</td>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>6.100000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>5.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Billing Amount</th>\n",
       "      <td>3.749098e+04</td>\n",
       "      <td>4.730406e+04</td>\n",
       "      <td>3.687490e+04</td>\n",
       "      <td>2.330332e+04</td>\n",
       "      <td>1.808634e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_0</th>\n",
       "      <td>5.122713e-12</td>\n",
       "      <td>8.400482e-23</td>\n",
       "      <td>8.891838e-12</td>\n",
       "      <td>1.877902e-03</td>\n",
       "      <td>9.239476e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_1</th>\n",
       "      <td>1.994086e-01</td>\n",
       "      <td>1.245006e-02</td>\n",
       "      <td>2.287377e-01</td>\n",
       "      <td>6.048713e-02</td>\n",
       "      <td>7.282988e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_2</th>\n",
       "      <td>1.642704e-05</td>\n",
       "      <td>3.638743e-12</td>\n",
       "      <td>2.561330e-05</td>\n",
       "      <td>2.972217e-01</td>\n",
       "      <td>5.082697e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_3</th>\n",
       "      <td>3.040007e-01</td>\n",
       "      <td>9.214652e-02</td>\n",
       "      <td>3.292812e-01</td>\n",
       "      <td>5.036247e-05</td>\n",
       "      <td>6.332398e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_4</th>\n",
       "      <td>8.496495e-03</td>\n",
       "      <td>4.215311e-06</td>\n",
       "      <td>1.503999e-02</td>\n",
       "      <td>3.531812e-01</td>\n",
       "      <td>1.189504e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_5</th>\n",
       "      <td>2.363898e-49</td>\n",
       "      <td>7.326256e-83</td>\n",
       "      <td>1.009836e-47</td>\n",
       "      <td>7.918352e-17</td>\n",
       "      <td>3.040046e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_6</th>\n",
       "      <td>1.536603e-05</td>\n",
       "      <td>1.744180e-08</td>\n",
       "      <td>8.763399e-05</td>\n",
       "      <td>1.232277e-01</td>\n",
       "      <td>2.581395e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_7</th>\n",
       "      <td>5.450355e-04</td>\n",
       "      <td>8.550531e-01</td>\n",
       "      <td>1.468219e-04</td>\n",
       "      <td>5.777418e-23</td>\n",
       "      <td>5.308288e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_8</th>\n",
       "      <td>2.382400e-02</td>\n",
       "      <td>9.146949e-05</td>\n",
       "      <td>5.853545e-02</td>\n",
       "      <td>1.620857e-01</td>\n",
       "      <td>1.493266e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component_9</th>\n",
       "      <td>4.636934e-01</td>\n",
       "      <td>4.025464e-02</td>\n",
       "      <td>3.681456e-01</td>\n",
       "      <td>1.868226e-03</td>\n",
       "      <td>2.994196e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0             1             2             3  \\\n",
       "Age             8.100000e+01  3.500000e+01  6.100000e+01  4.900000e+01   \n",
       "Billing Amount  3.749098e+04  4.730406e+04  3.687490e+04  2.330332e+04   \n",
       "0               0.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "1               0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "2               0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3               0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4               0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "5               0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00   \n",
       "6               0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "7               1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "8               0.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00   \n",
       "9               0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "10              1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "11              0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "12              0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "13              0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
       "14              0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00   \n",
       "15              0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "16              0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
       "17              0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "18              0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00   \n",
       "19              1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "20              0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00   \n",
       "Component_0     5.122713e-12  8.400482e-23  8.891838e-12  1.877902e-03   \n",
       "Component_1     1.994086e-01  1.245006e-02  2.287377e-01  6.048713e-02   \n",
       "Component_2     1.642704e-05  3.638743e-12  2.561330e-05  2.972217e-01   \n",
       "Component_3     3.040007e-01  9.214652e-02  3.292812e-01  5.036247e-05   \n",
       "Component_4     8.496495e-03  4.215311e-06  1.503999e-02  3.531812e-01   \n",
       "Component_5     2.363898e-49  7.326256e-83  1.009836e-47  7.918352e-17   \n",
       "Component_6     1.536603e-05  1.744180e-08  8.763399e-05  1.232277e-01   \n",
       "Component_7     5.450355e-04  8.550531e-01  1.468219e-04  5.777418e-23   \n",
       "Component_8     2.382400e-02  9.146949e-05  5.853545e-02  1.620857e-01   \n",
       "Component_9     4.636934e-01  4.025464e-02  3.681456e-01  1.868226e-03   \n",
       "\n",
       "                           4  \n",
       "Age             5.100000e+01  \n",
       "Billing Amount  1.808634e+04  \n",
       "0               1.000000e+00  \n",
       "1               0.000000e+00  \n",
       "2               0.000000e+00  \n",
       "3               0.000000e+00  \n",
       "4               0.000000e+00  \n",
       "5               0.000000e+00  \n",
       "6               0.000000e+00  \n",
       "7               1.000000e+00  \n",
       "8               0.000000e+00  \n",
       "9               0.000000e+00  \n",
       "10              0.000000e+00  \n",
       "11              0.000000e+00  \n",
       "12              0.000000e+00  \n",
       "13              0.000000e+00  \n",
       "14              1.000000e+00  \n",
       "15              0.000000e+00  \n",
       "16              0.000000e+00  \n",
       "17              1.000000e+00  \n",
       "18              0.000000e+00  \n",
       "19              0.000000e+00  \n",
       "20              1.000000e+00  \n",
       "Component_0     9.239476e-02  \n",
       "Component_1     7.282988e-03  \n",
       "Component_2     5.082697e-01  \n",
       "Component_3     6.332398e-08  \n",
       "Component_4     1.189504e-01  \n",
       "Component_5     3.040046e-09  \n",
       "Component_6     2.581395e-01  \n",
       "Component_7     5.308288e-34  \n",
       "Component_8     1.493266e-02  \n",
       "Component_9     2.994196e-05  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Training Data to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 33)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_train.to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building CTGAN Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, i, o):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fc = nn.Linear(i, o)\n",
    "        self.bn = nn.BatchNorm1d(o)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Residual layer to the `input_`.\"\"\"\n",
    "        out = self.fc(input_)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return torch.cat([out, input_], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, embedding_dim, generator_dim, data_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        dim = embedding_dim\n",
    "        seq = []\n",
    "        for item in list(generator_dim):\n",
    "            seq += [Residual(dim, item)]\n",
    "            dim += item\n",
    "        seq.append(nn.Linear(dim, data_dim))\n",
    "        self.seq = nn.Sequential(*seq)\n",
    "\n",
    "    def forward(self, z):\n",
    "        data = self.model(z)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, discriminator_dim, pac=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        dim = input_dim * pac\n",
    "        self.pac = pac\n",
    "        self.pacdim = dim\n",
    "        seq = []\n",
    "        for item in list(discriminator_dim):\n",
    "            seq += [nn.Linear(dim, item), nn.LeakyReLU(0.2), nn.Dropout(0.5)]\n",
    "            dim = item\n",
    "\n",
    "        seq += [nn.Linear(dim, 1)]\n",
    "        self.seq = nn.Sequential(*seq)\n",
    "\n",
    "    def calc_gradient_penalty(self, real_data, fake_data, device='cpu', pac=10, lambda_=10):\n",
    "        alpha = torch.rand(real_data.size(0) // pac, 1, 1, device=device)\n",
    "        alpha = alpha.repeat(1, pac, real_data.size(1))\n",
    "        alpha = alpha.view(-1, real_data.size(1))\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "        disc_interpolates = self(interpolates)\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=disc_interpolates, inputs=interpolates,\n",
    "            grad_outputs=torch.ones(disc_interpolates.size(), device=device),\n",
    "            create_graph=True, retain_graph=True, only_inputs=True\n",
    "        )[0]\n",
    "\n",
    "        gradients_view = gradients.view(-1, pac * real_data.size(1)).norm(2, dim=1) - 1\n",
    "        gradient_penalty = ((gradients_view) ** 2).mean() * lambda_\n",
    "\n",
    "        return gradient_penalty\n",
    "\n",
    "    def forward(self, input_):\n",
    "        assert input_.size()[0] % self.pac == 0\n",
    "        return self.seq(input_.view(-1, self.pacdim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Tabular GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTGAN():\n",
    "    \n",
    "    def __init__(self, embedding_dim=128, generator_dim=(256, 256), discriminator_dim=(256, 256),\n",
    "                 generator_lr=2e-4, generator_decay=1e-6, discriminator_lr=2e-4,\n",
    "                 discriminator_decay=1e-6, batch_size=500, discriminator_steps=1,\n",
    "                 log_frequency=True, verbose=False, epochs=300, pac=10, cuda=True):\n",
    "\n",
    "        assert batch_size % 2 == 0\n",
    "\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._generator_dim = generator_dim\n",
    "        self._discriminator_dim = discriminator_dim\n",
    "\n",
    "        self._generator_lr = generator_lr\n",
    "        self._generator_decay = generator_decay\n",
    "        self._discriminator_lr = discriminator_lr\n",
    "        self._discriminator_decay = discriminator_decay\n",
    "\n",
    "        self._batch_size = batch_size\n",
    "        self._discriminator_steps = discriminator_steps\n",
    "        self._log_frequency = log_frequency\n",
    "        self._verbose = verbose\n",
    "        self._epochs = epochs\n",
    "        self.pac = pac\n",
    "\n",
    "        if not cuda or not torch.cuda.is_available():\n",
    "            device = 'cpu'\n",
    "        elif isinstance(cuda, str):\n",
    "            device = cuda\n",
    "        else:\n",
    "            device = 'cuda'\n",
    "\n",
    "        self._device = torch.device(device)\n",
    "\n",
    "        self._transformer = None\n",
    "        self._data_sampler = None\n",
    "        self._generator = None\n",
    "        self.loss_values = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n",
    "        for _ in range(10):\n",
    "            transformed = nn.functional.gumbel_softmax(logits, tau=tau, hard=hard, eps=eps, dim=dim)\n",
    "            if not torch.isnan(transformed).any():\n",
    "                return transformed\n",
    "\n",
    "        raise ValueError('gumbel_softmax returning NaN.')\n",
    "\n",
    "    def _apply_activate(self, data):\n",
    "        \"\"\"Apply proper activation function to the output of the generator.\"\"\"\n",
    "        data_t = []\n",
    "        st = 0\n",
    "        for column_info in self._transformer.output_info_list:\n",
    "            for span_info in column_info:\n",
    "                if span_info.activation_fn == 'tanh':\n",
    "                    ed = st + span_info.dim\n",
    "                    data_t.append(torch.tanh(data[:, st:ed]))\n",
    "                    st = ed\n",
    "                elif span_info.activation_fn == 'softmax':\n",
    "                    ed = st + span_info.dim\n",
    "                    transformed = self._gumbel_softmax(data[:, st:ed], tau=0.2)\n",
    "                    data_t.append(transformed)\n",
    "                    st = ed\n",
    "                else:\n",
    "                    raise ValueError(f'Unexpected activation function {span_info.activation_fn}.')\n",
    "\n",
    "        return torch.cat(data_t, dim=1)\n",
    "\n",
    "    def _cond_loss(self, data, c, m):\n",
    "        \"\"\"Compute the cross entropy loss on the fixed discrete column.\"\"\"\n",
    "        loss = []\n",
    "        st = 0\n",
    "        st_c = 0\n",
    "        for column_info in self._transformer.output_info_list:\n",
    "            for span_info in column_info:\n",
    "                if len(column_info) != 1 or span_info.activation_fn != 'softmax':\n",
    "                    # not discrete column\n",
    "                    st += span_info.dim\n",
    "                else:\n",
    "                    ed = st + span_info.dim\n",
    "                    ed_c = st_c + span_info.dim\n",
    "                    tmp = nn.functional.cross_entropy(\n",
    "                        data[:, st:ed],\n",
    "                        torch.argmax(c[:, st_c:ed_c], dim=1),\n",
    "                        reduction='none'\n",
    "                    )\n",
    "                    loss.append(tmp)\n",
    "                    st = ed\n",
    "                    st_c = ed_c\n",
    "\n",
    "        loss = torch.stack(loss, dim=1)  # noqa: PD013\n",
    "\n",
    "        return (loss * m).sum() / data.size()[0]\n",
    "\n",
    "    def _validate_discrete_columns(self, train_data, discrete_columns):\n",
    "        \"\"\"Check whether ``discrete_columns`` exists in ``train_data``.\n",
    "\n",
    "        Args:\n",
    "            train_data (numpy.ndarray or pandas.DataFrame):\n",
    "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
    "            discrete_columns (list-like):\n",
    "                List of discrete columns to be used to generate the Conditional\n",
    "                Vector. If ``train_data`` is a Numpy array, this list should\n",
    "                contain the integer indices of the columns. Otherwise, if it is\n",
    "                a ``pandas.DataFrame``, this list should contain the column names.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, pd.DataFrame):\n",
    "            invalid_columns = set(discrete_columns) - set(train_data.columns)\n",
    "        elif isinstance(train_data, np.ndarray):\n",
    "            invalid_columns = []\n",
    "            for column in discrete_columns:\n",
    "                if column < 0 or column >= train_data.shape[1]:\n",
    "                    invalid_columns.append(column)\n",
    "        else:\n",
    "            raise TypeError('``train_data`` should be either pd.DataFrame or np.array.')\n",
    "\n",
    "        if invalid_columns:\n",
    "            raise ValueError(f'Invalid columns found: {invalid_columns}')\n",
    "\n",
    "    def fit(self, train_data, discrete_columns=(), epochs=None):\n",
    "        \"\"\"Fit the CTGAN Synthesizer models to the training data.\n",
    "\n",
    "        Args:\n",
    "            train_data (numpy.ndarray or pandas.DataFrame):\n",
    "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
    "            discrete_columns (list-like):\n",
    "                List of discrete columns to be used to generate the Conditional\n",
    "                Vector. If ``train_data`` is a Numpy array, this list should\n",
    "                contain the integer indices of the columns. Otherwise, if it is\n",
    "                a ``pandas.DataFrame``, this list should contain the column names.\n",
    "        \"\"\"\n",
    "        self._validate_discrete_columns(train_data, discrete_columns)\n",
    "\n",
    "        if epochs is None:\n",
    "            epochs = self._epochs\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                ('`epochs` argument in `fit` method has been deprecated and will be removed '\n",
    "                 'in a future version. Please pass `epochs` to the constructor instead'),\n",
    "                DeprecationWarning\n",
    "            )\n",
    "\n",
    "        train_data = self(train_data)\n",
    "\n",
    "        data_dim = self.output_dimensions\n",
    "\n",
    "        self._generator = Generator(\n",
    "            self._embedding_dim + self._data_sampler.dim_cond_vec(),\n",
    "            self._generator_dim,\n",
    "            data_dim\n",
    "        ).to(self._device)\n",
    "\n",
    "        discriminator = Discriminator(\n",
    "            data_dim + self._data_sampler.dim_cond_vec(),\n",
    "            self._discriminator_dim,\n",
    "            pac=self.pac\n",
    "        ).to(self._device)\n",
    "\n",
    "        optimizerG = optim.Adam(\n",
    "            self._generator.parameters(), lr=self._generator_lr, betas=(0.5, 0.9),\n",
    "            weight_decay=self._generator_decay\n",
    "        )\n",
    "\n",
    "        optimizerD = optim.Adam(\n",
    "            discriminator.parameters(), lr=self._discriminator_lr,\n",
    "            betas=(0.5, 0.9), weight_decay=self._discriminator_decay\n",
    "        )\n",
    "\n",
    "        mean = torch.zeros(self._batch_size, self._embedding_dim, device=self._device)\n",
    "        std = mean + 1\n",
    "\n",
    "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Generator Loss', 'Distriminator Loss'])\n",
    "\n",
    "        epoch_iterator = tqdm(range(epochs), disable=(not self._verbose))\n",
    "        if self._verbose:\n",
    "            description = 'Gen. ({gen:.2f}) | Discrim. ({dis:.2f})'\n",
    "            epoch_iterator.set_description(description.format(gen=0, dis=0))\n",
    "\n",
    "        steps_per_epoch = max(len(train_data) // self._batch_size, 1)\n",
    "        for i in epoch_iterator:\n",
    "            for id_ in range(steps_per_epoch):\n",
    "\n",
    "                for n in range(self._discriminator_steps):\n",
    "                    fakez = torch.normal(mean=mean, std=std)\n",
    "\n",
    "                    condvec = self._data_sampler.sample_condvec(self._batch_size)\n",
    "                    if condvec is None:\n",
    "                        c1, m1, col, opt = None, None, None, None\n",
    "                        real = self._data_sampler.sample_data(\n",
    "                            train_data, self._batch_size, col, opt)\n",
    "                    else:\n",
    "                        c1, m1, col, opt = condvec\n",
    "                        c1 = torch.from_numpy(c1).to(self._device)\n",
    "                        m1 = torch.from_numpy(m1).to(self._device)\n",
    "                        fakez = torch.cat([fakez, c1], dim=1)\n",
    "\n",
    "                        perm = np.arange(self._batch_size)\n",
    "                        np.random.shuffle(perm)\n",
    "                        real = self._data_sampler.sample_data(\n",
    "                            train_data, self._batch_size, col[perm], opt[perm])\n",
    "                        c2 = c1[perm]\n",
    "\n",
    "                    fake = self._generator(fakez)\n",
    "                    fakeact = self._apply_activate(fake)\n",
    "\n",
    "                    real = torch.from_numpy(real.astype('float32')).to(self._device)\n",
    "\n",
    "                    if c1 is not None:\n",
    "                        fake_cat = torch.cat([fakeact, c1], dim=1)\n",
    "                        real_cat = torch.cat([real, c2], dim=1)\n",
    "                    else:\n",
    "                        real_cat = real\n",
    "                        fake_cat = fakeact\n",
    "\n",
    "                    y_fake = discriminator(fake_cat)\n",
    "                    y_real = discriminator(real_cat)\n",
    "\n",
    "                    pen = discriminator.calc_gradient_penalty(\n",
    "                        real_cat, fake_cat, self._device, self.pac)\n",
    "                    loss_d = -(torch.mean(y_real) - torch.mean(y_fake))\n",
    "\n",
    "                    optimizerD.zero_grad(set_to_none=False)\n",
    "                    pen.backward(retain_graph=True)\n",
    "                    loss_d.backward()\n",
    "                    optimizerD.step()\n",
    "\n",
    "                fakez = torch.normal(mean=mean, std=std)\n",
    "                condvec = self._data_sampler.sample_condvec(self._batch_size)\n",
    "\n",
    "                if condvec is None:\n",
    "                    c1, m1, col, opt = None, None, None, None\n",
    "                else:\n",
    "                    c1, m1, col, opt = condvec\n",
    "                    c1 = torch.from_numpy(c1).to(self._device)\n",
    "                    m1 = torch.from_numpy(m1).to(self._device)\n",
    "                    fakez = torch.cat([fakez, c1], dim=1)\n",
    "\n",
    "                fake = self._generator(fakez)\n",
    "                fakeact = self._apply_activate(fake)\n",
    "\n",
    "                if c1 is not None:\n",
    "                    y_fake = discriminator(torch.cat([fakeact, c1], dim=1))\n",
    "                else:\n",
    "                    y_fake = discriminator(fakeact)\n",
    "\n",
    "                if condvec is None:\n",
    "                    cross_entropy = 0\n",
    "                else:\n",
    "                    cross_entropy = self._cond_loss(fake, c1, m1)\n",
    "\n",
    "                loss_g = -torch.mean(y_fake) + cross_entropy\n",
    "\n",
    "                optimizerG.zero_grad(set_to_none=False)\n",
    "                loss_g.backward()\n",
    "                optimizerG.step()\n",
    "\n",
    "            generator_loss = loss_g.detach().cpu().item()\n",
    "            discriminator_loss = loss_d.detach().cpu().item()\n",
    "\n",
    "            epoch_loss_df = pd.DataFrame({\n",
    "                'Epoch': [i],\n",
    "                'Generator Loss': [generator_loss],\n",
    "                'Discriminator Loss': [discriminator_loss]\n",
    "            })\n",
    "            if not self.loss_values.empty:\n",
    "                self.loss_values = pd.concat(\n",
    "                    [self.loss_values, epoch_loss_df]\n",
    "                ).reset_index(drop=True)\n",
    "            else:\n",
    "                self.loss_values = epoch_loss_df\n",
    "\n",
    "            if self._verbose:\n",
    "                epoch_iterator.set_description(\n",
    "                    description.format(gen=generator_loss, dis=discriminator_loss)\n",
    "                )\n",
    "\n",
    "    def sample(self, n, condition_column=None, condition_value=None):\n",
    "        \"\"\"Sample data similar to the training data.\n",
    "\n",
    "        Choosing a condition_column and condition_value will increase the probability of the\n",
    "        discrete condition_value happening in the condition_column.\n",
    "\n",
    "        Args:\n",
    "            n (int):\n",
    "                Number of rows to sample.\n",
    "            condition_column (string):\n",
    "                Name of a discrete column.\n",
    "            condition_value (string):\n",
    "                Name of the category in the condition_column which we wish to increase the\n",
    "                probability of happening.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray or pandas.DataFrame\n",
    "        \"\"\"\n",
    "        if condition_column is not None and condition_value is not None:\n",
    "            condition_info = self._transformer.convert_column_name_value_to_id(\n",
    "                condition_column, condition_value)\n",
    "            global_condition_vec = self._data_sampler.generate_cond_from_condition_column_info(\n",
    "                condition_info, self._batch_size)\n",
    "        else:\n",
    "            global_condition_vec = None\n",
    "\n",
    "        steps = n // self._batch_size + 1\n",
    "        data = []\n",
    "        for i in range(steps):\n",
    "            mean = torch.zeros(self._batch_size, self._embedding_dim)\n",
    "            std = mean + 1\n",
    "            fakez = torch.normal(mean=mean, std=std).to(self._device)\n",
    "\n",
    "            if global_condition_vec is not None:\n",
    "                condvec = global_condition_vec.copy()\n",
    "            else:\n",
    "                condvec = self._data_sampler.sample_original_condvec(self._batch_size)\n",
    "\n",
    "            if condvec is None:\n",
    "                pass\n",
    "            else:\n",
    "                c1 = condvec\n",
    "                c1 = torch.from_numpy(c1).to(self._device)\n",
    "                fakez = torch.cat([fakez, c1], dim=1)\n",
    "\n",
    "            fake = self._generator(fakez)\n",
    "            fakeact = self._apply_activate(fake)\n",
    "            data.append(fakeact.detach().cpu().numpy())\n",
    "\n",
    "        data = np.concatenate(data, axis=0)\n",
    "        data = data[:n]\n",
    "\n",
    "        return self._transformer.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
