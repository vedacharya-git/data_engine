{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data in pandas dataframe\n",
    "current_directory = os.path.abspath(os.getcwd())\n",
    "parent_directory = os.path.join(current_directory, '..')\n",
    "grandparent_directory = os.path.join(parent_directory, '..')\n",
    "data_directory = os.path.join(grandparent_directory, 'data')\n",
    "csv_path = os.path.join(data_directory, 'healthcare_dataset.csv')\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>Tiffany Ramirez</td>\n",
       "      <td>Ruben Burns</td>\n",
       "      <td>Chad Byrd</td>\n",
       "      <td>Antonio Frederick</td>\n",
       "      <td>Mrs. Brandy Flowers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>81</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>Female</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blood Type</th>\n",
       "      <td>O-</td>\n",
       "      <td>O+</td>\n",
       "      <td>B-</td>\n",
       "      <td>B-</td>\n",
       "      <td>O-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical Condition</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>Arthritis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Admission</th>\n",
       "      <td>2022-11-17</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2021-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>Patrick Parker</td>\n",
       "      <td>Diane Jackson</td>\n",
       "      <td>Paul Baker</td>\n",
       "      <td>Brian Chandler</td>\n",
       "      <td>Dustin Griffin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hospital</th>\n",
       "      <td>Wallace-Hamilton</td>\n",
       "      <td>Burke, Griffin and Cooper</td>\n",
       "      <td>Walton LLC</td>\n",
       "      <td>Garcia Ltd</td>\n",
       "      <td>Jones, Brown and Murray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insurance Provider</th>\n",
       "      <td>Medicare</td>\n",
       "      <td>UnitedHealthcare</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>UnitedHealthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Billing Amount</th>\n",
       "      <td>37490.983364</td>\n",
       "      <td>47304.064845</td>\n",
       "      <td>36874.896997</td>\n",
       "      <td>23303.322092</td>\n",
       "      <td>18086.344184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Room Number</th>\n",
       "      <td>146</td>\n",
       "      <td>404</td>\n",
       "      <td>292</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admission Type</th>\n",
       "      <td>Elective</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Urgent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharge Date</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2021-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medication</th>\n",
       "      <td>Aspirin</td>\n",
       "      <td>Lipitor</td>\n",
       "      <td>Lipitor</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Paracetamol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Results</th>\n",
       "      <td>Inconclusive</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0                          1             2  \\\n",
       "Name                 Tiffany Ramirez                Ruben Burns     Chad Byrd   \n",
       "Age                               81                         35            61   \n",
       "Gender                        Female                       Male          Male   \n",
       "Blood Type                        O-                         O+            B-   \n",
       "Medical Condition           Diabetes                     Asthma       Obesity   \n",
       "Date of Admission         2022-11-17                 2023-06-01    2019-01-09   \n",
       "Doctor                Patrick Parker              Diane Jackson    Paul Baker   \n",
       "Hospital            Wallace-Hamilton  Burke, Griffin and Cooper    Walton LLC   \n",
       "Insurance Provider          Medicare           UnitedHealthcare      Medicare   \n",
       "Billing Amount          37490.983364               47304.064845  36874.896997   \n",
       "Room Number                      146                        404           292   \n",
       "Admission Type              Elective                  Emergency     Emergency   \n",
       "Discharge Date            2022-12-01                 2023-06-15    2019-02-08   \n",
       "Medication                   Aspirin                    Lipitor       Lipitor   \n",
       "Test Results            Inconclusive                     Normal        Normal   \n",
       "\n",
       "                                    3                        4  \n",
       "Name                Antonio Frederick      Mrs. Brandy Flowers  \n",
       "Age                                49                       51  \n",
       "Gender                           Male                     Male  \n",
       "Blood Type                         B-                       O-  \n",
       "Medical Condition              Asthma                Arthritis  \n",
       "Date of Admission          2020-05-02               2021-07-09  \n",
       "Doctor                 Brian Chandler           Dustin Griffin  \n",
       "Hospital                   Garcia Ltd  Jones, Brown and Murray  \n",
       "Insurance Provider           Medicare         UnitedHealthcare  \n",
       "Billing Amount           23303.322092             18086.344184  \n",
       "Room Number                       480                      477  \n",
       "Admission Type                 Urgent                   Urgent  \n",
       "Discharge Date             2020-05-03               2021-08-02  \n",
       "Medication                 Penicillin              Paracetamol  \n",
       "Test Results                 Abnormal                   Normal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Name', 'Hospital', 'Doctor'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class to process data\n",
    "from DataProcessor_OLD import DataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions in the training loop\n",
    "def create_masks(N_d, m):\n",
    "    return torch.randint(0, 2, (m, N_d), dtype=torch.float32)\n",
    "\n",
    "def sample_z(m, latent_dim):\n",
    "    return torch.randn(m, latent_dim)\n",
    "\n",
    "def create_pacs(data, pac):\n",
    "    m = data.size(0)\n",
    "    return torch.stack([torch.bitwise_xor(data[k*pac:(k+1)*pac].int()).float() for k in range(m // pac)])\n",
    "\n",
    "def gradient_penalty(critic, real, fake, cond):\n",
    "    alpha = torch.rand(real.size(0), 1, device=real.device)\n",
    "    interpolates = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
    "    d_interpolates = critic(interpolates, cond)\n",
    "    fake_grad = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(d_interpolates),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    grad_penalty = ((fake_grad.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return grad_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ved/external/miniconda3/envs/da/lib/python3.10/site-packages/sklearn/base.py:1151: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/ved/external/miniconda3/envs/da/lib/python3.10/site-packages/sklearn/base.py:1151: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recieved sizes: 10000 5 40\n",
      "Device: cuda\n",
      "Data Size: 10000 | Batches per Epoch: 20 | PACs per Batch: 50\n",
      "Epoch 1/3\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "torch.Size([1, 100]) torch.Size([1, 45])\n",
      "torch.Size([1, 1605])\n",
      "Batch Number: 0 Pac Number: 0 Pac Count 9 Record number: 35.0\n",
      "\tExpected dim: 460 r_real_pac dim: torch.Size([450])\n",
      "\tExpected dim: 460 r_fake_pac dim: torch.Size([16050])\n",
      "torch.Size([1, 450]) torch.Size([1, 450]) Expected 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12350/2241439102.py:211: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"Batch Number:\", batch, \"Pac Number:\", pac_num, \"Pac Count\", l, \"Record number:\", row[0],flush=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x900 and 910x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 267\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m            for i in range(len(masks)):\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m                \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m            print(f\"Epoch: {epoch}, LossC: {LossC}\")\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    266\u001b[0m test \u001b[38;5;241m=\u001b[39m CTGAN(df)\n\u001b[0;32m--> 267\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 215\u001b[0m, in \u001b[0;36mCTGAN.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mExpected dim:\u001b[39m\u001b[38;5;124m'\u001b[39m, ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpac), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_real_pac dim:\u001b[39m\u001b[38;5;124m'\u001b[39m, r_real_pac\u001b[38;5;241m.\u001b[39mshape,flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mExpected dim:\u001b[39m\u001b[38;5;124m'\u001b[39m, ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpac), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_fake_pac dim:\u001b[39m\u001b[38;5;124m'\u001b[39m, r_fake_pac\u001b[38;5;241m.\u001b[39mshape,flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 215\u001b[0m C_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_real_pac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_pac\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m C_fake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(r_fake_pac, cond_pac)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCritic output shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, C_real\u001b[38;5;241m.\u001b[39mshape, C_fake\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/external/miniconda3/envs/da/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/external/miniconda3/envs/da/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 83\u001b[0m, in \u001b[0;36mCritic.forward\u001b[0;34m(self, r_pac, cond_pac)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(r_pac\u001b[38;5;241m.\u001b[39mshape, cond_pac\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim)\n\u001b[1;32m     81\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([r_pac, cond_pac], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky(h1)\n\u001b[1;32m     85\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(h1)\n",
      "File \u001b[0;32m~/external/miniconda3/envs/da/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/external/miniconda3/envs/da/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/external/miniconda3/envs/da/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x900 and 910x256)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, cond_dim, m, D):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.input_dim = z_dim + cond_dim\n",
    "        self.hidden_dim_1 = 256\n",
    "        self.hidden_dim_2 = 512\n",
    "        self.m = m\n",
    "        self.D = D\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_dim, self.hidden_dim_1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.hidden_dim_1)\n",
    "        \n",
    "        self.fc2 = nn.Linear(self.hidden_dim_1 + self.input_dim, self.hidden_dim_1)\n",
    "        self.bn2 = nn.BatchNorm1d(self.hidden_dim_1)\n",
    "        \n",
    "        self.alpha_layers = nn.ModuleList([nn.Linear(self.hidden_dim_2 + self.input_dim, 1) for _ in range(self.m)])\n",
    "        self.d_hat_layers = nn.ModuleList([nn.Linear(self.hidden_dim_2 + self.input_dim, self.D) for _ in range(self.D)])\n",
    "    \n",
    "    def forward(self, z, cond):\n",
    "        z = z.unsqueeze(0)\n",
    "        cond = cond.unsqueeze(0)\n",
    "        \n",
    "        print(z.shape, cond.shape)\n",
    "\n",
    "        h0 = torch.cat([z, cond], dim=1)\n",
    "\n",
    "        h1 = self.fc1(h0)\n",
    "        # h1 = self.bn1(h1)\n",
    "        h1 = F.relu(h1)\n",
    "        h1 = torch.cat([h0, h1], dim=1)\n",
    "        \n",
    "        h2 = self.fc2(h1)\n",
    "        # h2 = self.bn2(h2)\n",
    "        h2 = F.relu(h2)\n",
    "        h2 = torch.cat([h1, h2], dim=1)\n",
    "\n",
    "        # Generate continuous outputs\n",
    "        alpha = [torch.tanh(layer(h2)) for layer in self.alpha_layers]\n",
    "        \n",
    "        # Generate discrete outputs using Gumbel-Softmax\n",
    "        d_hat = [F.gumbel_softmax(layer(h2), tau=1.0, hard=True) for layer in self.d_hat_layers]\n",
    "        \n",
    "        # Concatenate all outputs\n",
    "        r = torch.cat(alpha + d_hat, dim=1)\n",
    "        print(r.shape)\n",
    "        return r\n",
    "\n",
    "# Critic\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, pac, r_dim, cond_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.pac = pac\n",
    "        self.input_dim = (r_dim + cond_dim) * pac\n",
    "        self.hidden_dim_1 = 256\n",
    "                \n",
    "        self.fc1 = nn.Linear(self.input_dim, self.hidden_dim_1)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(self.hidden_dim_1, self.hidden_dim_1)\n",
    "        \n",
    "        self.fc3 = nn.Linear(self.hidden_dim_1, 1)\n",
    "    \n",
    "    def forward(self, r_pac, cond_pac):\n",
    "        r_pac = r_pac.unsqueeze(0)\n",
    "        cond_pac = cond_pac.unsqueeze(0)\n",
    "        \n",
    "        print(r_pac.shape, cond_pac.shape, 'Expected', self.input_dim)\n",
    "                \n",
    "        h0 = torch.cat([r_pac, cond_pac], dim=1)\n",
    "        \n",
    "        h1 = self.fc1(h0)\n",
    "        h1 = self.leaky(h1)\n",
    "        h1 = self.drop(h1)\n",
    "        \n",
    "        h2 = self.fc2(h1)\n",
    "        h2 = self.leaky(h2)\n",
    "        h2 = self.drop(h2)\n",
    "        \n",
    "        C = self.fc3(h2)\n",
    "        \n",
    "        return C\n",
    "\n",
    "# CTGAN class\n",
    "class CTGAN:\n",
    "    def __init__(self, df, epochs=300, pac=10, batch_size=500):\n",
    "        self.df, self.m, self.D = DataProcessor(df).fit_transform()\n",
    "        self.size = df.shape[0]\n",
    "        self.epochs = epochs\n",
    "        self.pac = pac\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        print('Recieved sizes:', self.size, self.m, self.D)\n",
    "\n",
    "        self.df = self.df.sample(frac=1)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print('Device:', self.device)\n",
    "\n",
    "    def create_mask(self):\n",
    "        masks = []\n",
    "        ind = np.random.choice(self.df.index, self.batch_size, replace=False)\n",
    "        batch = self.df.loc[ind]\n",
    "        number_of_batches = max(self.df.shape[0] // self.batch_size, 1)\n",
    "        \n",
    "        for _ in range(number_of_batches):\n",
    "            batches = []\n",
    "            for _, rows in batch.iterrows():\n",
    "                condvec = rows.values.flatten().tolist()\n",
    "                batches.append(condvec)\n",
    "            masks.append(batches)\n",
    "        return np.array(masks)\n",
    "\n",
    "    def sampler(self, df, cond):\n",
    "        real_samples = torch.tensor([]).to(self.device)\n",
    "        cond_df = pd.DataFrame([cond], columns=df.columns)\n",
    "\n",
    "        # Filter training data based on the condition vector\n",
    "        filtered_data = df.copy()\n",
    "        for col in df.columns:\n",
    "            filtered_data = filtered_data[filtered_data[col] == cond_df[col].values[0]]\n",
    "\n",
    "        # Randomly sample from the filtered data\n",
    "        if not filtered_data.empty:\n",
    "            sample = filtered_data.sample(n=1).values\n",
    "            real_samples.append(sample)\n",
    "        else:\n",
    "            # Handle case where no samples match the condition\n",
    "            real_samples = torch.cat([real_samples,torch.tensor(np.zeros((1, df.shape[1]))).to(self.device)], axis=0)\n",
    "\n",
    "        return real_samples\n",
    "        \n",
    "\n",
    "    def Loss_G(self, real_pac, real_cond, fake_pac, fake_cond):\n",
    "        pass\n",
    "    \n",
    "    def Loss_C(self, real_pac, real_cond, fake_pac, fake_cond):\n",
    "        pass\n",
    "        \n",
    "    def train(self):\n",
    "        masks = self.create_mask()\n",
    "        latent_dim = 100\n",
    "        z = torch.randn(latent_dim).to(self.device)\n",
    "        \n",
    "        cond_dim = self.df.shape[1]\n",
    "        r_dim = self.m + self.D + 1\n",
    "                \n",
    "        self.generator = Generator(latent_dim, cond_dim, self.m, self.D).to(self.device)\n",
    "        self.critic = Critic(self.pac, r_dim, cond_dim).to(self.device)\n",
    "        \n",
    "        self.optimizerG = optim.Adam(\n",
    "            self.generator.parameters(),\n",
    "            lr=2e-4,\n",
    "            betas=(0.5, 0.9),\n",
    "            weight_decay=1e-6\n",
    "        )\n",
    "        self.optimizerC = optim.Adam(\n",
    "            self.critic.parameters(),\n",
    "            lr=2e-4,\n",
    "            betas=(0.5, 0.9),\n",
    "            weight_decay=1e-6\n",
    "        )\n",
    "        \n",
    "        data_size = len(self.df)\n",
    "        pacs_per_batch = self.batch_size // self.pac\n",
    "        batches_per_epoch = data_size // self.batch_size\n",
    "        \n",
    "        print(f\"Data Size: {data_size} | Batches per Epoch: {batches_per_epoch} | PACs per Batch: {pacs_per_batch}\")\n",
    "        \n",
    "        ###### CHANGE THIS\n",
    "        self.epochs = 3\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Epoch {epoch + 1}/{self.epochs}')\n",
    "            \n",
    "            for batch in range(batches_per_epoch):\n",
    "                batch_start = batch * self.batch_size\n",
    "                batch_end = (batch + 1) * self.batch_size\n",
    "                batch_df = self.df.iloc[batch_start:batch_end]\n",
    "                \n",
    "                for pac_num in range(pacs_per_batch):\n",
    "                    pac_start = pac_num * self.pac\n",
    "                    pac_end = min(pac_start + self.pac, len(batch_df))\n",
    "                    pac_df = batch_df.iloc[pac_start:pac_end]\n",
    "                    cond_pac = torch.tensor([]).to(self.device).float()\n",
    "                    r_real_pac = torch.tensor([]).to(self.device).float()\n",
    "                    r_fake_pac = torch.tensor([]).to(self.device).float()\n",
    "                    \n",
    "                    for l, (index, row) in enumerate(pac_df.iterrows()):\n",
    "                        cond = torch.tensor(row.values).float().to(self.device)\n",
    "                        r_real = self.sampler(self.df, cond).to(self.device).float()\n",
    "                        r_fake = self.generator(z, cond).to(self.device).float()\n",
    "                                                \n",
    "                        cond_pac = torch.cat([cond_pac, cond], dim=0).to(self.device).float()\n",
    "                        r_real_pac = torch.cat([r_real_pac, r_real], dim=1).to(self.device).float()\n",
    "                        r_fake_pac = torch.cat([r_fake_pac, r_fake], dim=1).to(self.device).float()\n",
    "                                        \n",
    "                    r_real_pac = r_real_pac.reshape(-1)\n",
    "                    r_fake_pac = r_fake_pac.reshape(-1)\n",
    "                    \n",
    "                    print(\"Batch Number:\", batch, \"Pac Number:\", pac_num, \"Pac Count\", l, \"Record number:\", row[0],flush=True)\n",
    "                    print('\\tExpected dim:', ((self.m + self.D + 1) * self.pac), 'r_real_pac dim:', r_real_pac.shape,flush=True)\n",
    "                    print('\\tExpected dim:', ((self.m + self.D + 1) * self.pac), 'r_fake_pac dim:', r_fake_pac.shape,flush=True)\n",
    "                    \n",
    "                    C_real = self.critic(r_real_pac, cond_pac)\n",
    "                    C_fake = self.critic(r_fake_pac, cond_pac)\n",
    "                    \n",
    "                    print('Critic output shape:', C_real.shape, C_fake.shape)\n",
    "\n",
    "            \n",
    "'''\n",
    "                        print('Epoch', i + 1, 'Batch Number:', batch, 'Pac Number:', pac_num, 'Pac Count', l, 'Record number:', row[0], flush=True)\n",
    "                    pac_start_index += self.pac\n",
    "                    print('Finished One Pac', flush=True)\n",
    "                start_index += self.batch_size\n",
    "                print('Finished One Batch', flush=True)\n",
    "            print('--------------------------------------------------')\n",
    "'''\n",
    "'''\n",
    "            for i in range(len(masks)):\n",
    "                \n",
    "                for j in range(len(masks) // self.pac):\n",
    "                    cond = torch.tensor(mask[0]).float().to(self.device)\n",
    "                    print('Shape of condition: ', cond.shape)\n",
    "                    r_pac_fake = self.generator(z, cond).to(self.device)\n",
    "                    print('Shape of fake data: ', r_pac_fake.shape)\n",
    "                    \n",
    "                    r_pac_real = self.sampler(self.df, cond).to(self.device)\n",
    "                    print('Shape of real data: ', r_pac_real.shape)\n",
    "                    \n",
    "                    cond_pac = cond.to(self.device)\n",
    "                    C_real, C_fake = 0, 0\n",
    "                    for _ in range(self.pac - 1):\n",
    "                        cond = torch.tensor(mask).float().to(self.device)\n",
    "                        cond_pac = torch.cat([cond_pac, cond], dim=1).to(self.device)\n",
    "                        \n",
    "                        r_fake = self.generator(z, cond).to(self.device)\n",
    "                        r_real = self.sampler(self.df, cond).to(self.device)\n",
    "                                                \n",
    "                        r_pac_fake = torch.cat([r_pac_fake, r_fake], dim=1).to(self.device)\n",
    "                        r_pac_real = torch.cat([r_pac_real, r_real], dim=1).to(self.device)\n",
    "                    \n",
    "                    C_real += self.critic(r_pac_real, cond_pac)\n",
    "                    C_fake += self.critic(r_pac_fake, cond_pac)\n",
    "                    \n",
    "                    LossC = C_fake.mean() - C_real.mean()\n",
    "                    \n",
    "                    \n",
    "                    self.optimizerG.zero_grad()\n",
    "                    self.optimizerC.zero_grad()\n",
    "                    \n",
    "                    self.optimizerC.zero_grad()\n",
    "\n",
    "            print(f\"Epoch: {epoch}, LossC: {LossC}\")\n",
    "'''\n",
    "test = CTGAN(df)\n",
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp, m, D = DataProcessor(df).fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 500\n",
    "pac_size = 10\n",
    "device = 'cuda'\n",
    "\n",
    "data_size = len(dp)\n",
    "pacs_per_batch = batch_size // pac_size\n",
    "batches_per_epoch = data_size // batch_size\n",
    "\n",
    "print(f\"Data Size: {data_size} | Batches per Epoch: {batches_per_epoch} | PACs per Batch: {pacs_per_batch}\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for batch in range(batches_per_epoch):\n",
    "        batch_start = batch * batch_size\n",
    "        batch_end = min(batch_start + batch_size, data_size)\n",
    "        batch_df = dp.iloc[batch_start:batch_end]\n",
    "        print(f\"  Batch {batch + 1}/{batches_per_epoch}\")\n",
    "\n",
    "        for pac_num in range(pacs_per_batch):\n",
    "            pac_start = pac_num * pac_size\n",
    "            pac_end = min(pac_start + pac_size, len(batch_df))\n",
    "            pac_df = batch_df.iloc[pac_start:pac_end]\n",
    "            print(f\"    Pac {pac_num + 1}/{pacs_per_batch}\")\n",
    "            cond_pac = torch.tensor([]).to(device)\n",
    "\n",
    "            for l, (index, row) in enumerate(pac_df.iterrows()):\n",
    "                cond = torch.tensor(row.values).to(device)\n",
    "                cond_pac = torch.cat((cond_pac, cond), dim=0)\n",
    "    print(\"--------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
